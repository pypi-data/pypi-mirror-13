<workflow-app xmlns="uri:oozie:workflow:0.3" name="test-core_examples_java_cloner">
	<!-- This workflow demonstrates how to apply a simple Java workflow node 
		on data consisting of person records. The Java workflow node does not do 
		anything intelligent - it just creates a given number of copies of each input 
		record Note that documentation placed in comments in this file uses the "markdown" 
		syntax (along with division into sections). -->
	<start to="producer" />
	<action name="producer">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<!-- The data generated by this node is deleted in this section -->
			<prepare>
				<delete path="${nameNode}${workingDir}/producer" />
				<mkdir path="${nameNode}${workingDir}/producer" />
			</prepare>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
			</configuration>
			<!-- This is simple wrapper for the Java code -->
			<main-class>eu.dnetlib.iis.core.java.ProcessWrapper</main-class>
			<!-- The business Java code that gets to be executed -->
			<arg>eu.dnetlib.iis.core.java.jsonworkflownodes.Producer</arg>
			<!-- Specification of the output ports -->
			<arg>-C{person,
				eu.dnetlib.iis.core.examples.schemas.documentandauthor.Person,
				eu/dnetlib/iis/core/examples/data/person.json}
			</arg>
			<!-- All input and output ports have to be bound to paths in HDFS -->
			<arg>-Operson=${workingDir}/producer/person</arg>
		</java>
		<ok to="cloner" />
		<error to="fail" />
	</action>
	<action name="cloner">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<!-- The data generated by this node is deleted in this section -->
			<prepare>
				<delete path="${nameNode}${workingDir}/cloner" />
				<mkdir path="${nameNode}${workingDir}/cloner" />
			</prepare>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
			</configuration>
			<!-- This is simple wrapper for the Java code -->
			<main-class>eu.dnetlib.iis.core.java.ProcessWrapper</main-class>
			<!-- The business Java code that gets to be executed -->
			<arg>eu.dnetlib.iis.core.examples.java.PersonCloner</arg>
			<!-- All input and output ports have to be bound to paths in HDFS -->
			<arg>-Iperson=${workingDir}/producer/person</arg>
			<arg>-Operson=${workingDir}/cloner/person</arg>
			<arg>-Pcopies=3</arg>
		</java>
		<ok to="consumer" />
		<error to="fail" />
	</action>
	
	<action name="consumer">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
			</configuration>
			<main-class>eu.dnetlib.iis.core.java.ProcessWrapper</main-class>
			<arg>eu.dnetlib.iis.core.java.jsonworkflownodes.TestingConsumer</arg>
			<arg>-C{data,
				eu.dnetlib.iis.core.examples.schemas.documentandauthor.Person,
				eu/dnetlib/iis/core/examples/java/data/person.json}
			</arg>
			<arg>-Idata=${workingDir}/cloner/person</arg>
		</java>
		<ok to="end" />
		<error to="fail" />
	</action>
	
	<kill name="fail">
		<message>Unfortunately, the process failed -- error message:
			[${wf:errorMessage(wf:lastErrorNode())}]
		</message>
	</kill>
	<end name="end" />
</workflow-app>
